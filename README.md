##Welcome
This repository is meant to track my progress as I study transformers by attemptiong to recreate the results of the famous paper "Attention is all you need". I will be using these two resources to guide my progress:
 - https://github.com/google/flax/tree/main/examples/wmt
 - https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial6/Transformers_and_MHAttention.html
